{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setup\n",
        "\n",
        "Run first"
      ],
      "metadata": {
        "id": "w_fRFl5sUnvA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install vaderSentiment"
      ],
      "metadata": {
        "id": "o4ZrazPrUjqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "from scipy import spatial\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "oNClFCrjUk8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sentiment Analysis"
      ],
      "metadata": {
        "id": "0QtxQ2slUx_i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Start VADER\n",
        "\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "word = 'search find'\n",
        "vs = analyzer.polarity_scores(word)\n",
        "print(\"{:-<65} {}\".format(word, str(vs)))"
      ],
      "metadata": {
        "id": "VxKCqjxSUmjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converts text to a SA vector through VADER\n",
        "\n",
        "def text_2_sent_vec(text):\n",
        "  vs = analyzer.polarity_scores(text)\n",
        "  sent_vec = np.zeros((len(vs)))\n",
        "  for idx, key in enumerate(vs):\n",
        "    sent_vec[idx] = vs[key]\n",
        "\n",
        "  return sent_vec"
      ],
      "metadata": {
        "id": "TmwAGfLdU8fd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_2_sent_vec(\"funeral somber\")"
      ],
      "metadata": {
        "id": "QZSu3RW5U9rM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a2Ycb-c_UBoj"
      },
      "outputs": [],
      "source": [
        "# Testing analogy pairs with VADER\n",
        "\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "questions = [[\"diamond:baseball\", \"court:poker\", \"court:jury\", \"court:grass\", \"court:squash\", 4],\n",
        "             [\"bench:judge\", \"throne:king\", \"queen:king\", \"court:king\", \"knight:king\", 3],\n",
        "             [\"funeral:somber\", \"tension:festive\", \"soiree:festive\", \"eulogy:festive\", \"sari:festive\", 2],\n",
        "             [\"defeat:vanquish\", \"search:peer\", \"search:ransack\", \"search:destroy\", \"search:find\", 4],\n",
        "             [\"slug:land\", \"shark:seaweed\", \"shark:ocean\", \"shark:sky\", \"shark:slide\", 2]]\n",
        "\n",
        "analogy_predictions = []\n",
        "\n",
        "for p in range(0, len(questions)):\n",
        "  print(\"Q\"+ str(p+1) +\":\")\n",
        "  q = questions[p]\n",
        "  \n",
        "  a = q[0].split(':')\n",
        "  a_combined = a[0] + ' ' + a[1]\n",
        "  a_vec = text_2_sent_vec(a_combined)\n",
        "  print(a_vec)\n",
        "\n",
        "  sim_scores = []\n",
        "  for i in range(1,5):\n",
        "    b = q[i].split(':')\n",
        "    b_combined = b[0] + ' ' + b[1]\n",
        "    b_vec = text_2_sent_vec(b_combined)\n",
        "    print(b_vec)\n",
        "\n",
        "    sim = 1 - spatial.distance.cosine(a_vec, b_vec)\n",
        "    sim_scores.append(sim)\n",
        "\n",
        "  print(\"Similarities:\")\n",
        "  print(sim_scores)\n",
        "  analogy_predictions.append(np.argmax(sim_scores)+1)\n",
        "  print()\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "print(\"-----\")\n",
        "\n",
        "correct_anal = 0\n",
        "for i in range (0,len(questions)):\n",
        "  if questions[i][5] == analogy_predictions[i]:\n",
        "    print(\"Correct answer for Question #\" + str(i+1))\n",
        "  else:\n",
        "    print(\"Incorrect answer for Question #\" + str(i+1))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing with synonyms/antonyms\n",
        "\n",
        "# Need CSV from Project 3\n",
        "syntest = pd.read_csv(\"syntest.csv\")\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "prediction_list = []\n",
        "\n",
        "for k in range(0,len(syntest)):\n",
        "  t = syntest.loc[k]\n",
        "  q = text_2_sent_vec(t.loc[\"Question\"])\n",
        "  sim_scores = []\n",
        "  for i in range(1,5):\n",
        "    sim = 1 - spatial.distance.cosine(q, text_2_sent_vec(t.loc[\"Answer\"+str(i)]))\n",
        "    sim_scores.append(sim)\n",
        "\n",
        "  # Use print to see all computed similarity scores\n",
        "  #print(k+1, sim_scores)\n",
        "  if t.loc[\"Type\"] == 'synonym':\n",
        "    prediction = t.loc[\"Answer\"+str(np.argmax(sim_scores) + 1)]\n",
        "  else:\n",
        "    prediction = t.loc[\"Answer\"+str(np.argmin(sim_scores) + 1)]\n",
        "\n",
        "  if prediction == t.loc[\"Correct\"]:\n",
        "    prediction_list.append(1)\n",
        "  else:\n",
        "    prediction_list.append(0)\n",
        "\n",
        "print(\"Correct answers: \" + str(np.count_nonzero(prediction_list)) +\"/\"+ str(len(prediction_list)) )"
      ],
      "metadata": {
        "id": "37E8U1sMU_v5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}